# ğŸ¯ Emotion Classification Using Facial Expressions and EEG  

This repository contains all code, data pipelines, models, and notebooks developed as part of the **IITB EdTech Internship 2025 (Group T1_G38 â€“ Team_Attackers)** for **Problem ID 4: Emotion Classification using Facial Expressions and EEG**.

---

## ğŸ“‘ Project Overview  

**Objective:** Predict emotions (e.g. Engaged, Confused, Neutral) from EEG and Affectiva facial expression data.  

**Modalities:**  
- **EEG**: Delta, Theta, Alpha, Beta, Gamma bands  
- **Facial Expressions**: Affectiva probabilities & Action Units from TIVA  

**Key Challenges:** Temporal alignment of multimodal data and class imbalance.  

---

## ğŸ“‚ Project Structure  

Based on the project structure you've provided, here is a correct and complete description for your `README.md` file. It consolidates all the information from your screenshots and the project plan into a clear, single format.

-----

### ğŸ“‚ Project Structure

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ EEG_combined.csv # Preprocessed and synchronized EEG features.
â”‚   â”œâ”€â”€ PSY_combined.csv # Preprocessed and synchronized behavioral data.
â”‚   â”œâ”€â”€ TIVA_combined.csv # Preprocessed and synchronized Affectiva facial features.
â”‚   â”œâ”€â”€ WINDOW_combined.csv # The core dataset after applying the sliding window approach.
â”‚   â””â”€â”€ df_features_trials.csv # A trial-level dataset with final labels and features.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_preprocessing.ipynb # Notebook for data cleaning, merging, and initial synchronization.
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb # Notebook for extracting and combining multimodal features.
â”‚   â”œâ”€â”€ 03_modeling_baseline.ipynb # Notebook for training and evaluating baseline ML models (RF, XGBoost, LR).
â”‚   â”œâ”€â”€ 04_temporal_models.ipynb # Notebook dedicated to implementing and training the BiLSTM with attention.
â”‚   â”œâ”€â”€ 05_modeling_fusion.ipynb # Notebook for exploring different fusion techniques (early, late, intermediate).
â”‚   â””â”€â”€ 06_analysis.ipynb # Notebook for in-depth model evaluation, interpretation, and visualization.
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rf_allfeatures.pkl # A trained Scikit-learn Random Forest model on all features.
â”‚   â”œâ”€â”€ xg_allfeatures.pkl # A trained Scikit-learn XGBoost model on all features.
â”‚   â”œâ”€â”€ logreg_scalefeatures.pkl # A trained Scikit-learn Logistic Regression model on scaled features.
â”‚   â”œâ”€â”€ rf_eeg.pkl # A trained Random Forest model using only EEG features.
â”‚   â”œâ”€â”€ rf_tiva_latefusion.pkl # A trained Random Forest model using only TIVA features for late fusion.
â”‚   â”œâ”€â”€ rf_eeg_latefusion.pkl # A trained Random Forest model using only EEG features for late fusion.
â”‚   â”œâ”€â”€ rf_earlyfusion.pkl # A trained Random Forest model on concatenated EEG and TIVA features.
â”‚   â”œâ”€â”€ mlp_intermidatefusion.pkl # A trained MLP model for intermediate fusion.
â”‚   â””â”€â”€ multimodal_bilstm_attention.pth # A trained PyTorch BiLSTM model with attention.
â””â”€â”€ README.md # The project's main documentation and overview.
```


---

## ğŸ—‚ Data Access  

Raw and processed data are hosted on Google Drive:  
[ğŸ“¥ IITB Dataset Folder](https://drive.google.com/drive/folders/1t0SB-wcesioeYdzdGwnte3m-vxgmYkCc?usp=sharing)

**Within Drive:**  
- `IITB/Data/processed` contains combined/cleaned data used in this repository.  
- `IITB/project` contains notebooks and scripts.  

Because the `data/` folder is large, youâ€™ll need to download the files and place them in the correct directory before running the notebooks.

**How to Use the Data:**  
1. Download from the Google Drive link above.  
2. In your local repository, create a `data/` folder (if not already).  
3. Move the downloaded files (`EEG_combined.csv`, `TIVA_combined.csv`, `PSY_combined.csv`, `WINDOW_combined.csv`, `df_features_trials.csv`) into the `data/` folder.  
4. Run the notebooks â€“ they will automatically load the data from `data/`.  

---

## ğŸš€ Steps Implemented (matching internship tasks)  

### 1ï¸âƒ£ Preprocessing  
- Combined EEG, TIVA, PSY data across 38 students  
- Cleaned missing values & handled NaNs  
- Synchronized timestamps using `routineStart`/`routineEnd`  
- Downsampled to ~2.3 Hz per label  

### 2ï¸âƒ£ Feature Engineering  
- **EEG**: mean/variance for Delta, Theta, Alpha, Beta, Gamma; frontal asymmetry, engagement index  
- **Facial**: raw Affectiva emotion probabilities (Joy, Anger, Fearâ€¦) and Action Units (AUs) aggregated per trial (mean/std/max/occurrence)  

### 3ï¸âƒ£ Modeling  
- **Baseline (03_modeling_baseline):** RF, XGBoost, Logistic Regression on concatenated EEG+TIVA features. Models:  
  - `rf_allfeatures.pkl`  
  - `xg_allfeatures.pkl`  
  - `logreg_scalefeatures.pkl`  

- **Fusion (05_modeling_fusion):**  
  - **Early fusion:** concatenate EEG+facial features â†’ classifier (`rf_earlyfusion.pkl`)  
  - **Late fusion:** separate models per modality, combine logits (`rf_eeg_latefusion.pkl`, `rf_tiva_latefusion.pkl`)  
  - **Intermediate fusion:** embeddings from CNN + EEG MLP â†’ joint classifier (`mlp_intermidatefusion.pkl`)  

- **Advanced (04_temporal_models):** BiLSTM with attention for temporal modeling (`multimodal_bilstm_attention.pth`)  

### 4ï¸âƒ£ Evaluation & Interpretation (06_analysis)  
- Accuracy, macro F1, precision, recall  
- Confusion Matrix per class  
- ROC-AUC for binary subsets (e.g., Engaged vs Not Engaged)  
- SHAP values to interpret EEG bandpower and AUs importance  
- Attention weights visualization to see modality dominance  

### 5ï¸âƒ£ Experimentation & Improvement  
- Tested different time-window sizes  
- Oversampling with SMOTE for underrepresented emotions  
- Participant-specific vs cross-participant splits  
- Continuous dimensions (Valence, Arousal)  
- Temporal smoothing of predictions (HMM / majority vote)  

---

## ğŸ“Š How to Reproduce  

1. Clone this repo.  
2. Install requirements:
   ```bash
   pip install -r requirements.txt
3. Mount your Google Drive or ensure data/ and models/ are in place.

4. Run notebooks in order:
  â†’ 01_preprocessing.ipynb 
  â†’ 02_feature_engineering.ipynb 
  â†’ 03_modeling_baseline.ipynb 
  â†’ 04_temporal_models.ipynb 
  â†’ 05_modeling_fusion.ipynb 
  â†’ 06_analysis.ipynb

5. Load trained models:
  import joblib
  rf = joblib.load('models/rf_allfeatures.pkl')

  import torch
  model = MyBiLSTMModel(...)
  model.load_state_dict(torch.load('models/multimodal_bilstm_attention.pth'))
  model.eval()


## ğŸ“ˆ Results (Test Set)

| Model                          | Accuracy | Macro F1 |
|-------------------------------|----------|----------|
| Random Forest (All Features)  | 0.61     | 0.28     |
| XGBoost (All Features)        | 0.64     | 0.27     |
| Logistic Regression (Scaled)  | 0.41     | 0.25     |
| Random Forest (EEG only)      | 0.71     | 0.21     |
| Random Forest (Early Fusion)  | 0.60     | 0.28     |
| Random Forest (Late Fusion)   | 0.72     | 0.21     |
| MLP (Intermediate Fusion)     | 0.61     | 0.26     |
| BiLSTM + Attention            | 0.60     | 0.25     |

ğŸ“ Notes

All .pkl models use joblib.

PyTorch models are saved as .pth.


ğŸ‘¥ Team

Group T1_G38 â€“ Team_Attackers

Members:

Pranav Chandrakant Patil

Harshad Balaso Kanire

Omkar Manik Patil

Faculty Mentor: Mr. Swapnil T. Powar
 

7. 
